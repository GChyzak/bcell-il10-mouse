{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological pathway activity inference\n",
    "\n",
    "Using DecoupleR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pyorthomap import findOrthologsMmHs\n",
    "import decoupler as dc\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants\n",
    "save_folder = \"figures/\"\n",
    "objects_folder = \"saved_objects/\"\n",
    "sc.settings.figdir = './'+save_folder\n",
    "\n",
    "plt.rcParams['figure.figsize']=(8,8) #rescale figures\n",
    "sc.settings.verbosity = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-processed data\n",
    "\n",
    "with open('saved_objects/adata_annotated.pkl', 'rb') as inp:\n",
    "    adata = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['log_il10'] = adata.X[:, adata.var['gene_name'] == 'Il10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbdcfae16874000bf22ad8bc790f2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to human gene names\n",
    "\n",
    "def replace(x):\n",
    "    if len(x.tolist()) == 1:\n",
    "        if x.tolist()[0] != x.tolist()[0]:\n",
    "            return \"NA\"\n",
    "        else:\n",
    "            return(x.tolist()[0])\n",
    "    else:\n",
    "        return \"NA\"\n",
    "\n",
    "translated = findOrthologsMmHs(from_filters = 'external_gene_name',\n",
    "                               from_values = adata.var.index.tolist()).map()\n",
    "adata.var['human_name'] = [replace(translated[translated.external_gene_name == e][\"hgnc_symbol\"]) for e in adata.var['gene_name']]\n",
    "\n",
    "adata = adata[:,~(adata.var.human_name == \"NA\")]\n",
    "adata.var = adata.var[~(adata.var.human_name == \"NA\")]\n",
    "adata.var = adata.var.set_index(\"human_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata0 = adata.copy()\n",
    "adata1 = adata[adata.obs['cond'] == 'N6'].copy()\n",
    "adata2 = adata[adata.obs['tp'] == '48h'].copy()\n",
    "adata3 = adata[adata.obs['sample2'] == 'N6-48h'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA\n",
      "    on highly variable genes\n",
      "    with n_comps=50\n",
      "    finished (0:00:07)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 10:54:22.431137: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/lib/R/lib:\n",
      "2022-06-24 10:54:22.431223: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m [adata1, adata2, adata3]:\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39m# Calculate the visualizations\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m     sc\u001b[39m.\u001b[39mpp\u001b[39m.\u001b[39mpca(data, n_comps\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, use_highly_variable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, svd_solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m     sc\u001b[39m.\u001b[39;49mpp\u001b[39m.\u001b[39;49mneighbors(data)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m     sc\u001b[39m.\u001b[39mtl\u001b[39m.\u001b[39mumap(data)\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/scanpy/neighbors/__init__.py:139\u001b[0m, in \u001b[0;36mneighbors\u001b[0;34m(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy)\u001b[0m\n\u001b[1;32m    137\u001b[0m     adata\u001b[39m.\u001b[39m_init_as_actual(adata\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m    138\u001b[0m neighbors \u001b[39m=\u001b[39m Neighbors(adata)\n\u001b[0;32m--> 139\u001b[0m neighbors\u001b[39m.\u001b[39;49mcompute_neighbors(\n\u001b[1;32m    140\u001b[0m     n_neighbors\u001b[39m=\u001b[39;49mn_neighbors,\n\u001b[1;32m    141\u001b[0m     knn\u001b[39m=\u001b[39;49mknn,\n\u001b[1;32m    142\u001b[0m     n_pcs\u001b[39m=\u001b[39;49mn_pcs,\n\u001b[1;32m    143\u001b[0m     use_rep\u001b[39m=\u001b[39;49muse_rep,\n\u001b[1;32m    144\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    145\u001b[0m     metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    146\u001b[0m     metric_kwds\u001b[39m=\u001b[39;49mmetric_kwds,\n\u001b[1;32m    147\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m key_added \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     key_added \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mneighbors\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/scanpy/neighbors/__init__.py:794\u001b[0m, in \u001b[0;36mNeighbors.compute_neighbors\u001b[0;34m(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds)\u001b[0m\n\u001b[1;32m    792\u001b[0m     X \u001b[39m=\u001b[39m pairwise_distances(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmetric_kwds)\n\u001b[1;32m    793\u001b[0m     metric \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 794\u001b[0m knn_indices, knn_distances, forest \u001b[39m=\u001b[39m compute_neighbors_umap(\n\u001b[1;32m    795\u001b[0m     X, n_neighbors, random_state, metric\u001b[39m=\u001b[39;49mmetric, metric_kwds\u001b[39m=\u001b[39;49mmetric_kwds\n\u001b[1;32m    796\u001b[0m )\n\u001b[1;32m    797\u001b[0m \u001b[39m# very cautious here\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/scanpy/neighbors/__init__.py:301\u001b[0m, in \u001b[0;36mcompute_neighbors_umap\u001b[0;34m(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    299\u001b[0m     \u001b[39m# umap 0.5.0\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensorflow not installed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mumap\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mumap_\u001b[39;00m \u001b[39mimport\u001b[39;00m nearest_neighbors\n\u001b[1;32m    303\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[1;32m    305\u001b[0m knn_indices, knn_dists, forest \u001b[39m=\u001b[39m nearest_neighbors(\n\u001b[1;32m    306\u001b[0m     X,\n\u001b[1;32m    307\u001b[0m     n_neighbors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    313\u001b[0m )\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/umap/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mwith\u001b[39;00m catch_warnings():\n\u001b[1;32m      6\u001b[0m         simplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparametric_umap\u001b[39;00m \u001b[39mimport\u001b[39;00m ParametricUMAP\n\u001b[1;32m      8\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     warn(\n\u001b[1;32m     10\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTensorflow not installed; ParametricUMAP will be unavailable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mImportWarning\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/umap/parametric_umap.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     warn(\n\u001b[1;32m     17\u001b[0m         \u001b[39m\"\"\"The umap.parametric_umap package requires Tensorflow > 2.0 to be installed.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m    You can install Tensorflow at https://www.tensorflow.org/install\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/__init__.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     44\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/data/__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/data/experimental/__init__.py:95\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m service\n\u001b[1;32m     96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m     97\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/data/experimental/service/__init__.py:387\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mThis module contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m    388\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    389\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_server_lib\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_ops\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m options \u001b[39mas\u001b[39;00m options_lib\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m structured_function\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:31\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m graph_pb2\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m iterator_ops\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m options \u001b[39mas\u001b[39;00m options_lib\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m structured_function\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m type_spec\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_dataset_ops\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaver\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseSaverBuilder\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtracking\u001b[39;00m \u001b[39mimport\u001b[39;00m base \u001b[39mas\u001b[39;00m trackable\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m trace\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/training/saver.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m device \u001b[39mas\u001b[39;00m pydev\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m errors\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m meta_graph\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/framework/meta_graph.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m error_interpolation\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m graph_io\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m importer\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_def_registry\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/framework/importer.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m device \u001b[39mas\u001b[39;00m pydev\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m errors\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m function\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_def_registry\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/framework/function.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m resource_variable_ops\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m variable_scope \u001b[39mas\u001b[39;00m vs\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_array_ops\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_resource_variable_ops\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_state_ops\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m handle_data_util\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:839\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:934\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1033\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in [adata1, adata2, adata3]:\n",
    "    # Calculate the visualizations\n",
    "    sc.pp.pca(data, n_comps=50, use_highly_variable=True, svd_solver='arpack')\n",
    "    sc.pp.neighbors(data)\n",
    "\n",
    "    sc.tl.umap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"all\", \"N6\", \"48h\", \"N6-48h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DecoupleR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decoupler(data, net, groupkey, name):\n",
    "    \n",
    "    mat = pd.DataFrame(data.X, columns = data.var_names, index = data.obs_names)\n",
    "\n",
    "    test = dc.decouple(mat=mat, net=net, methods = ['mlm', 'ulm', 'ora', 'aucell'],verbose=True)\n",
    "\n",
    "    data.obsm['test_estimate'], data.obsm['test_pvals'] = test['consensus_estimate'], test['consensus_pvals']\n",
    "    acts = dc.get_acts(data, obsm_key='test_estimate')\n",
    "    mean_acts = dc.summarize_acts(acts, groupby=groupkey, min_std=0.1) #0.3\n",
    "    diffs = abs(mean_acts.diff().iloc[1,:])\n",
    "    mean_acts = mean_acts.filter(diffs.nlargest(30).index.tolist())\n",
    "    rats = mean_acts.pct_change().iloc[1,:]\n",
    "\n",
    "    l = diffs.nlargest(min(len(diffs//2), 3)).index.tolist() + rats.nsmallest(min(len(diffs//2), 3)).index.tolist()\n",
    "    sc.pl.umap(acts, color=l+['log_il10', groupkey], cmap='coolwarm', vcenter=0, size = 40, ncols=4, show=False, save=\"_\"+name+\".pdf\")\n",
    "    \n",
    "    mean_acts = mean_acts.filter(rats.nlargest(min(len(rats//2), 15)).index.tolist() + rats.nsmallest(min(len(rats//2), 15)).index.tolist())\n",
    "    plot = sb.clustermap(mean_acts, center=0, xticklabels=mean_acts.columns, cmap='coolwarm')\n",
    "    plot.fig.savefig(save_folder+\"heatmap_\"+name+\".pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_upr(data, net, groupkey, name):\n",
    "    \n",
    "    mat = pd.DataFrame(data.X, columns = data.var_names, index = data.obs_names)\n",
    "    test = dc.decouple(mat=mat, net=net, methods = ['mlm', 'ulm', 'ora', 'aucell'],verbose=True)\n",
    "\n",
    "    data.obsm['test_estimate'], data.obsm['test_pvals'] = test['consensus_estimate'], test['consensus_pvals']\n",
    "    acts = dc.get_acts(data, obsm_key='test_estimate')\n",
    "\n",
    "    sc.pl.umap(acts, color=['HALLMARK_UNFOLDED_PROTEIN_RESPONSE', groupkey], cmap='coolwarm', vcenter=0, size = 40, ncols=4, show=False, save=\"_upr_\"+name+\".pdf\")\n",
    "\n",
    "    marker = 'Il10'\n",
    "    sc.tl.embedding_density(data, basis='umap', groupby=marker+'_positive')\n",
    "    sc.pl.embedding_density(data, basis='umap', key='umap_density_'+marker+'_positive', group=marker+'+', save=\"_upr_\"+name+\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functional enrichment of 'Hallmark' gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HALLMARK_TNFA_SIGNALING_VIA_NFKB</td>\n",
       "      <td>MSC</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>HALLMARK_TNFA_SIGNALING_VIA_NFKB</td>\n",
       "      <td>ICOSLG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>HALLMARK_INFLAMMATORY_RESPONSE</td>\n",
       "      <td>ICOSLG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>HALLMARK_ALLOGRAFT_REJECTION</td>\n",
       "      <td>ICOSLG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>HALLMARK_HYPOXIA</td>\n",
       "      <td>FOSL2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878342</th>\n",
       "      <td>HALLMARK_PANCREAS_BETA_CELLS</td>\n",
       "      <td>FOXO1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878418</th>\n",
       "      <td>HALLMARK_PANCREAS_BETA_CELLS</td>\n",
       "      <td>GCG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878512</th>\n",
       "      <td>HALLMARK_PANCREAS_BETA_CELLS</td>\n",
       "      <td>PDX1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878605</th>\n",
       "      <td>HALLMARK_PANCREAS_BETA_CELLS</td>\n",
       "      <td>INS</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878785</th>\n",
       "      <td>HALLMARK_PANCREAS_BETA_CELLS</td>\n",
       "      <td>SRP9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7318 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label                             source  target  weight\n",
       "11      HALLMARK_TNFA_SIGNALING_VIA_NFKB     MSC     1.0\n",
       "149     HALLMARK_TNFA_SIGNALING_VIA_NFKB  ICOSLG     1.0\n",
       "223       HALLMARK_INFLAMMATORY_RESPONSE  ICOSLG     1.0\n",
       "270         HALLMARK_ALLOGRAFT_REJECTION  ICOSLG     1.0\n",
       "398                     HALLMARK_HYPOXIA   FOSL2     1.0\n",
       "...                                  ...     ...     ...\n",
       "878342      HALLMARK_PANCREAS_BETA_CELLS   FOXO1     1.0\n",
       "878418      HALLMARK_PANCREAS_BETA_CELLS     GCG     1.0\n",
       "878512      HALLMARK_PANCREAS_BETA_CELLS    PDX1     1.0\n",
       "878605      HALLMARK_PANCREAS_BETA_CELLS     INS     1.0\n",
       "878785      HALLMARK_PANCREAS_BETA_CELLS    SRP9     1.0\n",
       "\n",
       "[7318 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = dc.get_resource('MSigDB')\n",
    "# Filter by hallmark\n",
    "net = net[net['collection']=='hallmark']\n",
    "\n",
    "# Remove duplicated entries\n",
    "net = net[~net.duplicated(['geneset', 'genesymbol'])]\n",
    "net = dc.rename_net(net, source='geneset', target='genesymbol', weight=None)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adata0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m analysis_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHM_\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m run_decoupler(adata0, net, \u001b[39m'\u001b[39m\u001b[39msample2\u001b[39m\u001b[39m'\u001b[39m, analysis_name\u001b[39m+\u001b[39mnames[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m run_decoupler(adata1, net, \u001b[39m'\u001b[39m\u001b[39mtp\u001b[39m\u001b[39m'\u001b[39m, analysis_name\u001b[39m+\u001b[39mnames[\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m run_decoupler(adata2, net, \u001b[39m'\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m'\u001b[39m, analysis_name\u001b[39m+\u001b[39mnames[\u001b[39m2\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adata0' is not defined"
     ]
    }
   ],
   "source": [
    "analysis_name = \"HM_\"\n",
    "run_decoupler(adata0, net, 'sample2', analysis_name+names[0])\n",
    "run_decoupler(adata1, net, 'tp', analysis_name+names[1])\n",
    "run_decoupler(adata2, net, 'cond', analysis_name+names[2])\n",
    "run_decoupler(adata3, net, 'Il10_positive', analysis_name+names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mlm on mat with 37425 samples and 10561 targets for 50 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:54<00:00, 13.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ulm on mat with 37425 samples and 10561 targets for 50 sources.\n",
      "Running ora on mat with 37425 samples and 10561 targets for 50 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37425/37425 [03:10<00:00, 196.62it/s]\n",
      "/opt/python/lib/python3.8/site-packages/pandas/core/internals/blocks.py:402: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=0'>1</a>\u001b[0m analysis_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHM_\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=1'>2</a>\u001b[0m run_upr(adata0, net, \u001b[39m'\u001b[39;49m\u001b[39msample2\u001b[39;49m\u001b[39m'\u001b[39;49m, analysis_name\u001b[39m+\u001b[39;49mnames[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=2'>3</a>\u001b[0m run_upr(adata1, net, \u001b[39m'\u001b[39m\u001b[39mtp\u001b[39m\u001b[39m'\u001b[39m, analysis_name\u001b[39m+\u001b[39mnames[\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=3'>4</a>\u001b[0m run_upr(adata2, net, \u001b[39m'\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m'\u001b[39m, analysis_name\u001b[39m+\u001b[39mnames[\u001b[39m2\u001b[39m])\n",
      "\u001b[1;32m/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb Cell 18'\u001b[0m in \u001b[0;36mrun_upr\u001b[0;34m(data, net, groupkey, name)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_upr\u001b[39m(data, net, groupkey, name):\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=2'>3</a>\u001b[0m     mat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m.\u001b[39mX, columns \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mvar_names, index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mobs_names)\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=3'>4</a>\u001b[0m     test \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49mdecouple(mat\u001b[39m=\u001b[39;49mmat, net\u001b[39m=\u001b[39;49mnet, methods \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mmlm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mulm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mora\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39maucell\u001b[39;49m\u001b[39m'\u001b[39;49m],verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=5'>6</a>\u001b[0m     data\u001b[39m.\u001b[39mobsm[\u001b[39m'\u001b[39m\u001b[39mtest_estimate\u001b[39m\u001b[39m'\u001b[39m], data\u001b[39m.\u001b[39mobsm[\u001b[39m'\u001b[39m\u001b[39mtest_pvals\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test[\u001b[39m'\u001b[39m\u001b[39mconsensus_estimate\u001b[39m\u001b[39m'\u001b[39m], test[\u001b[39m'\u001b[39m\u001b[39mconsensus_pvals\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c245c5562756e74755c686f6d655c6775696c6c5f755c73635f7475746f5f75/workspaces/sc_tuto_u/scripts_publi/7-DecoupleR.ipynb#ch0000018vscode-remote?line=6'>7</a>\u001b[0m     acts \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mget_acts(data, obsm_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest_estimate\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/decoupler/decouple.py:140\u001b[0m, in \u001b[0;36mdecouple\u001b[0;34m(mat, net, source, target, weight, methods, args, consensus, cns_metds, min_n, verbose, use_raw)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMethod name \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in args not found in methods, will be ignored.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(methd))\n\u001b[1;32m    139\u001b[0m \u001b[39m# Run methods\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m results \u001b[39m=\u001b[39m run_methods(mat, net, source, target, weight, methods, args, min_n, verbose, use_raw)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Run consensus score\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m consensus:\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/decoupler/decouple.py:50\u001b[0m, in \u001b[0;36mrun_methods\u001b[0;34m(mat, net, source, target, weight, methods, args, min_n, verbose, use_raw)\u001b[0m\n\u001b[1;32m     48\u001b[0m     res \u001b[39m=\u001b[39m f(mat\u001b[39m=\u001b[39mmat, net\u001b[39m=\u001b[39mnet, source\u001b[39m=\u001b[39msource, target\u001b[39m=\u001b[39mtarget, weight\u001b[39m=\u001b[39mweight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39ma)\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     res \u001b[39m=\u001b[39m f(mat\u001b[39m=\u001b[39;49mmat, net\u001b[39m=\u001b[39;49mnet, source\u001b[39m=\u001b[39;49msource, target\u001b[39m=\u001b[39;49mtarget, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49ma)\n\u001b[1;32m     52\u001b[0m \u001b[39m# Extract for AnnData\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/decoupler/method_aucell.py:117\u001b[0m, in \u001b[0;36mrun_aucell\u001b[0;34m(mat, net, source, target, n_up, min_n, seed, verbose, use_raw)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mAUCell.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m    AUCell scores. Stored in `.obsm['aucell_estimate']` if `mat` is AnnData.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# Extract sparse matrix and array of genes\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m m, r, c \u001b[39m=\u001b[39m extract(mat, use_raw\u001b[39m=\u001b[39;49muse_raw, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    119\u001b[0m \u001b[39m# Set n_up\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m n_up \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/decoupler/pre.py:42\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(mat, use_raw, verbose, dtype)\u001b[0m\n\u001b[1;32m     40\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(c)\n\u001b[1;32m     41\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(mat) \u001b[39mis\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m---> 42\u001b[0m     m \u001b[39m=\u001b[39m csr_matrix(mat\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m     43\u001b[0m     r \u001b[39m=\u001b[39m mat\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     44\u001b[0m     c \u001b[39m=\u001b[39m mat\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/scipy/sparse/_compressed.py:85\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munrecognized \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_matrix constructor usage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\n\u001b[0;32m---> 85\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coo_container(arg1, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m     86\u001b[0m     ))\n\u001b[1;32m     88\u001b[0m \u001b[39m# Read matrix dimensions given, if any\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/python/lib/python3.8/site-packages/scipy/sparse/_coo.py:189\u001b[0m, in \u001b[0;36mcoo_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39mif\u001b[39;00m check_shape(shape) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape:\n\u001b[1;32m    186\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minconsistent shapes: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    187\u001b[0m                          (shape, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape))\n\u001b[0;32m--> 189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39;49mnonzero()\n\u001b[1;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m M[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol]\n\u001b[1;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_canonical_format \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "analysis_name = \"HM_\"\n",
    "run_upr(adata0, net, 'sample2', analysis_name+names[0])\n",
    "run_upr(adata1, net, 'tp', analysis_name+names[1])\n",
    "run_upr(adata2, net, 'cond', analysis_name+names[2])\n",
    "run_upr(adata3, net, 'Il10_positive', analysis_name+names[3])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fd198094d18c1f6e835bbc10f230f9f1bc4929522b005bc69d9b1e47e35dda8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
